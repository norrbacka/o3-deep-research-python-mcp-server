Your goal and mission is to build a MCP Server that does deep research using the o3-deep-research Azure Open AI solution.

Inside the folder "resources" you have different document to support you. For instance:

 - @resources/grok_heavys_thinking.md which gives you a full implementation guideline from a senor python expert. Follow this guidelines in your implementation in an mentorship way. However... Use Gemini CLI Tool if you want to "search this one" since it takes a lot of context.
 - @recources/gemini_thinking.md as ane ven deeper look at solving this problem based on the grok-review. You can use this for guidance as well. Use Gemini CLI Tool if you want to "search this one" since it takes a lot of context.
 - @resources/microsoft_docs.md where you can read the basic documentation ofr O3 Deep research from Azure
 - @resources/python-sdk-llm.txt which gives you all information on the FastMCP python SDK which you will use for implementation. Use Gemini CLI Tool if you want to "search this one" since it takes a lot of context.
 - @resources/sample_agents_deep_research_async.py which is a basic small example of a O3 Deep Research Azure Open AI integration from Microsoft. What is good about this one is that it is offifical example. The sample_agents_deep_research_async.py is not good enough to use as a base. You can read it for knowledge. BUt the information in gemini_thinking.md and grok_heavys_thinking.md is much better.     

And make your own task list. Also I expect you to build this server in 1 hour. So track the time, and do not stop until atleast 30 minutes have gone. Crafting this server takes time. And as good coders you and I am, we need to let it take time.
